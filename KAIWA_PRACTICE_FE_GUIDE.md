# H∆∞·ªõng D·∫´n T√≠ch H·ª£p Kaiwa Practice API cho Frontend (React Vite)

## üìã M·ª•c L·ª•c
1. [T·ªïng Quan](#t·ªïng-quan)
2. [C√†i ƒê·∫∑t Dependencies](#c√†i-ƒë·∫∑t-dependencies)
3. [Record Audio trong React](#record-audio-trong-react)
4. [Format Audio (Base64 Encoding)](#format-audio-base64-encoding)
5. [API Endpoints](#api-endpoints)
6. [Code Examples](#code-examples)
7. [X·ª≠ L√Ω Response](#x·ª≠-l√Ω-response)
8. [Error Handling](#error-handling)
9. [Best Practices](#best-practices)

---

## üéØ T·ªïng Quan

Kaiwa Practice l√† t√≠nh nƒÉng luy·ªán n√≥i ti·∫øng Nh·∫≠t gi·ªëng Elsa Speak, cho ph√©p:
- User ch·ªçn tr√¨nh ƒë·ªô JLPT (N5-N1)
- Record audio ph√°t √¢m c√¢u ti·∫øng Nh·∫≠t
- Nh·∫≠n feedback v·ªÅ ƒë·ªô ch√≠nh x√°c v√† ph√°t √¢m
- So s√°nh v·ªõi c√¢u m·∫´u

**Lu·ªìng ho·∫°t ƒë·ªông:**
1. User ch·ªçn level (N5-N1)
2. L·∫•y c√¢u m·∫´u t·ª´ API (ho·∫∑c t·ª± nh·∫≠p)
3. Record audio
4. Convert audio sang Base64
5. G·ª≠i l√™n BE ƒë·ªÉ ph√¢n t√≠ch
6. Nh·∫≠n k·∫øt qu·∫£ v√† hi·ªÉn th·ªã

---

## üì¶ C√†i ƒê·∫∑t Dependencies

### 1. Install c√°c package c·∫ßn thi·∫øt:

```bash
npm install axios
# ho·∫∑c
yarn add axios
```

### 2. C√°c API Browser c·∫ßn thi·∫øt (built-in, kh√¥ng c·∫ßn install):
- `navigator.mediaDevices.getUserMedia()` - Record audio
- `MediaRecorder API` - X·ª≠ l√Ω audio recording
- `FileReader API` - Convert audio sang Base64

---

## üé§ Record Audio trong React

### Hook ƒë·ªÉ Record Audio:

```typescript
// hooks/useAudioRecorder.ts
import { useState, useRef, useCallback } from 'react';

interface UseAudioRecorderReturn {
  isRecording: boolean;
  audioBlob: Blob | null;
  startRecording: () => Promise<void>;
  stopRecording: () => void;
  resetRecording: () => void;
  error: string | null;
}

export const useAudioRecorder = (): UseAudioRecorderReturn => {
  const [isRecording, setIsRecording] = useState(false);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const [error, setError] = useState<string | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);

  const startRecording = useCallback(async () => {
    try {
      setError(null);
      
      // Request microphone permission
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          channelCount: 1,        // Mono
          sampleRate: 16000,      // 16kHz (recommended for Japanese)
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      });

      // Create MediaRecorder with WAV format
      const mimeType = 'audio/webm;codecs=opus'; // Fallback to webm
      const options: MediaRecorderOptions = {
        mimeType: mimeType,
        audioBitsPerSecond: 128000
      };

      const mediaRecorder = new MediaRecorder(stream, options);
      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        const blob = new Blob(chunksRef.current, { type: 'audio/webm' });
        setAudioBlob(blob);
        
        // Stop all tracks to release microphone
        stream.getTracks().forEach(track => track.stop());
      };

      mediaRecorder.onerror = (event) => {
        setError('Recording error occurred');
        console.error('MediaRecorder error:', event);
      };

      mediaRecorder.start();
      setIsRecording(true);
    } catch (err) {
      console.error('Error starting recording:', err);
      setError('Failed to access microphone. Please check permissions.');
    }
  }, []);

  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
  }, [isRecording]);

  const resetRecording = useCallback(() => {
    setAudioBlob(null);
    setError(null);
    chunksRef.current = [];
  }, []);

  return {
    isRecording,
    audioBlob,
    startRecording,
    stopRecording,
    resetRecording,
    error
  };
};
```

---

## üîÑ Format Audio (Base64 Encoding)

### Convert Audio Blob sang Base64:

```typescript
// utils/audioUtils.ts

/**
 * Convert audio Blob sang Base64 string
 * @param audioBlob - Audio Blob t·ª´ MediaRecorder
 * @returns Promise<string> - Base64 encoded string
 */
export const convertBlobToBase64 = (audioBlob: Blob): Promise<string> => {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    
    reader.onloadend = () => {
      if (typeof reader.result === 'string') {
        // Remove data URL prefix (data:audio/webm;base64,)
        const base64String = reader.result.split(',')[1];
        resolve(base64String);
      } else {
        reject(new Error('Failed to convert blob to base64'));
      }
    };
    
    reader.onerror = () => {
      reject(new Error('Error reading audio file'));
    };
    
    reader.readAsDataURL(audioBlob);
  });
};

/**
 * Convert audio Blob sang WAV format (n·∫øu c·∫ßn)
 * Note: Browser th∆∞·ªùng record WebM/Opus, BE s·∫Ω t·ª± convert
 */
export const getAudioFormat = (blob: Blob): string => {
  if (blob.type.includes('webm')) {
    return 'webm'; // BE s·∫Ω convert sang wav
  }
  if (blob.type.includes('wav')) {
    return 'wav';
  }
  if (blob.type.includes('mp3')) {
    return 'mp3';
  }
  return 'wav'; // Default
};

/**
 * Validate audio size (max 10MB)
 */
export const validateAudioSize = (blob: Blob): boolean => {
  const maxSize = 10 * 1024 * 1024; // 10MB
  return blob.size <= maxSize;
};
```

---

## üåê API Endpoints

### Base URL:
```
Production: https://your-api-domain.com/api/ai
Development: http://localhost:8080/api/ai
```

### 1. L·∫•y c√¢u m·∫´u theo Level
```typescript
GET /api/ai/kaiwa-sentences/{level}
// level: N5, N4, N3, N2, N1

Response:
{
  "success": true,
  "message": "Suggested sentences for N5",
  "data": {
    "level": "N5",
    "sentences": [
      {
        "text": "„Åì„Çì„Å´„Å°„ÅØ",
        "translation": "Xin ch√†o",
        "difficulty": "easy"
      },
      // ...
    ],
    "count": 10
  }
}
```

### 2. L·∫•y c√¢u ng·∫´u nhi√™n
```typescript
GET /api/ai/kaiwa-sentences/{level}/random

Response:
{
  "success": true,
  "message": "Random sentence for N5",
  "data": {
    "text": "ÁßÅ„ÅØÊó•Êú¨Ë™û„ÇíÂãâÂº∑„Åó„Å¶„ÅÑ„Åæ„Åô",
    "translation": "T√¥i ƒëang h·ªçc ti·∫øng Nh·∫≠t",
    "difficulty": "medium"
  }
}
```

### 3. L·∫•y recommendations cho level
```typescript
GET /api/ai/kaiwa-recommendations/{level}

Response:
{
  "success": true,
  "message": "Kaiwa recommendations for N5",
  "data": {
    "level": "N5",
    "recommendedSpeed": "normal",
    "recommendedSpeakingRate": 1.0,
    "levelInfo": {
      "level": "N5",
      "description": "Recommended settings for N5 level practice"
    }
  }
}
```

### 4. **Kaiwa Practice (Main API)**
```typescript
POST /api/ai/kaiwa-practice

Request Body:
{
  "targetText": "ÁßÅ„ÅØÊó•Êú¨Ë™û„ÇíÂãâÂº∑„Åó„Å¶„ÅÑ„Åæ„Åô",  // Required
  "audioData": "UklGRiQAAABXQVZFZm10IBAAAAAB...", // Required (Base64)
  "level": "N5",                              // Optional (default: N5)
  "language": "ja-JP",                       // Optional (default: ja-JP)
  "audioFormat": "wav"                       // Optional (default: wav)
}

Response:
{
  "success": true,
  "message": "Kaiwa practice completed",
  "data": {
    "targetText": "ÁßÅ„ÅØÊó•Êú¨Ë™û„ÇíÂãâÂº∑„Åó„Å¶„ÅÑ„Åæ„Åô",
    "userTranscript": "ÁßÅ„ÅØÊó•Êú¨Ë™û„ÇíÂãâÂº∑„Åó„Å¶„ÅÑ„Åæ„Åô",
    "level": "N5",
    "accuracyScore": 0.95,           // 0-1 (95%)
    "pronunciationScore": 0.88,       // 0-1 (88%)
    "overallScore": 0.92,             // 0-1 (92%)
    "confidence": 0.88,               // Speech recognition confidence
    "isAccurate": true,               // accuracyScore >= threshold
    "needsPractice": false,           // overallScore < threshold
    "feedback": {
      "overallFeedbackVi": "Ph√°t √¢m xu·∫•t s·∫Øc! B·∫°n ƒë√£ n√≥i r·∫•t ch√≠nh x√°c.",
      "accuracyFeedbackVi": "ƒê·ªô ch√≠nh x√°c: 95%. B·∫°n ƒë√£ ph√°t √¢m ƒë√∫ng c√¢u.",
      "pronunciationFeedbackVi": "Ph√°t √¢m t·ªët! (ƒë·ªô ch√≠nh x√°c: 88%)",
      "suggestionsVi": "Ti·∫øp t·ª•c luy·ªán t·∫≠p ƒë·ªÉ c·∫£i thi·ªán ph√°t √¢m.",
      "pronunciationTips": [
        "Ch√∫ √Ω ph√°t √¢m r√µ r√†ng c√°c t·ª´",
        "Luy·ªán t·∫≠p ng·ªØ ƒëi·ªáu t·ª± nhi√™n"
      ],
      "levelInfo": {
        "level": "N5",
        "levelNameVi": "S∆° c·∫•p",
        "descriptionVi": "Tr√¨nh ƒë·ªô c∆° b·∫£n nh·∫•t"
      }
    },
    "recommendations": {
      "recommendedSpeed": "normal",
      "recommendedSpeakingRate": 1.0,
      "tolerance": 0.15,
      "accuracyThreshold": 0.75,
      "practiceThreshold": 0.7
    }
  }
}
```

---

## üíª Code Examples

### 1. Service ƒë·ªÉ g·ªçi API:

```typescript
// services/kaiwaService.ts
import axios from 'axios';

const API_BASE_URL = import.meta.env.VITE_API_BASE_URL || 'http://localhost:8080/api/ai';

interface KaiwaPracticeRequest {
  targetText: string;
  audioData: string;        // Base64 string
  level?: string;            // N5, N4, N3, N2, N1
  language?: string;         // ja-JP (default)
  audioFormat?: string;      // wav, mp3, flac, ogg
}

interface KaiwaPracticeResponse {
  success: boolean;
  message: string;
  data: {
    targetText: string;
    userTranscript: string;
    level: string;
    accuracyScore: number;
    pronunciationScore: number;
    overallScore: number;
    confidence: number;
    isAccurate: boolean;
    needsPractice: boolean;
    feedback: {
      overallFeedbackVi: string;
      accuracyFeedbackVi: string;
      pronunciationFeedbackVi: string;
      suggestionsVi: string;
      pronunciationTips: string[];
      levelInfo: {
        level: string;
        levelNameVi: string;
        descriptionVi: string;
      };
    };
    recommendations: {
      recommendedSpeed: string;
      recommendedSpeakingRate: number;
      tolerance: number;
      accuracyThreshold: number;
      practiceThreshold: number;
    };
  };
}

export const kaiwaService = {
  /**
   * L·∫•y danh s√°ch c√¢u m·∫´u theo level
   */
  async getSuggestedSentences(level: string): Promise<any> {
    const response = await axios.get(`${API_BASE_URL}/kaiwa-sentences/${level}`);
    return response.data;
  },

  /**
   * L·∫•y c√¢u ng·∫´u nhi√™n
   */
  async getRandomSentence(level: string): Promise<any> {
    const response = await axios.get(`${API_BASE_URL}/kaiwa-sentences/${level}/random`);
    return response.data;
  },

  /**
   * L·∫•y recommendations cho level
   */
  async getRecommendations(level: string): Promise<any> {
    const response = await axios.get(`${API_BASE_URL}/kaiwa-recommendations/${level}`);
    return response.data;
  },

  /**
   * G·ª≠i audio ƒë·ªÉ practice
   */
  async practiceKaiwa(request: KaiwaPracticeRequest): Promise<KaiwaPracticeResponse> {
    const response = await axios.post(
      `${API_BASE_URL}/kaiwa-practice`,
      request,
      {
        headers: {
          'Content-Type': 'application/json',
        },
        timeout: 30000, // 30 seconds timeout
      }
    );
    return response.data;
  },
};
```

### 2. Component s·ª≠ d·ª•ng:

```typescript
// components/KaiwaPractice.tsx
import { useState } from 'react';
import { useAudioRecorder } from '../hooks/useAudioRecorder';
import { convertBlobToBase64, validateAudioSize } from '../utils/audioUtils';
import { kaiwaService } from '../services/kaiwaService';

export const KaiwaPractice = () => {
  const [level, setLevel] = useState<string>('N5');
  const [targetText, setTargetText] = useState<string>('');
  const [result, setResult] = useState<any>(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const {
    isRecording,
    audioBlob,
    startRecording,
    stopRecording,
    resetRecording,
    error: recordingError,
  } = useAudioRecorder();

  // L·∫•y c√¢u ng·∫´u nhi√™n
  const loadRandomSentence = async () => {
    try {
      setLoading(true);
      const response = await kaiwaService.getRandomSentence(level);
      if (response.success) {
        setTargetText(response.data.text);
        setResult(null);
      }
    } catch (err: any) {
      setError(err.message || 'Failed to load sentence');
    } finally {
      setLoading(false);
    }
  };

  // Submit audio ƒë·ªÉ practice
  const handlePractice = async () => {
    if (!audioBlob) {
      setError('Please record audio first');
      return;
    }

    if (!targetText.trim()) {
      setError('Please enter or select a target sentence');
      return;
    }

    // Validate audio size
    if (!validateAudioSize(audioBlob)) {
      setError('Audio file is too large (max 10MB)');
      return;
    }

    try {
      setLoading(true);
      setError(null);

      // Convert audio to Base64
      const base64Audio = await convertBlobToBase64(audioBlob);

      // Call API
      const response = await kaiwaService.practiceKaiwa({
        targetText: targetText,
        audioData: base64Audio,
        level: level,
        language: 'ja-JP',
        audioFormat: 'wav', // BE s·∫Ω t·ª± convert n·∫øu c·∫ßn
      });

      if (response.success) {
        setResult(response.data);
      } else {
        setError(response.message || 'Practice failed');
      }
    } catch (err: any) {
      console.error('Practice error:', err);
      setError(
        err.response?.data?.message || 
        err.message || 
        'Failed to process practice. Please try again.'
      );
    } finally {
      setLoading(false);
    }
  };

  return (
    <div>
      {/* Level Selection */}
      <select 
        value={level} 
        onChange={(e) => {
          setLevel(e.target.value);
          setResult(null);
          setTargetText('');
        }}
      >
        <option value="N5">N5 - S∆° c·∫•p</option>
        <option value="N4">N4 - S∆° trung c·∫•p</option>
        <option value="N3">N3 - Trung c·∫•p</option>
        <option value="N2">N2 - Trung cao c·∫•p</option>
        <option value="N1">N1 - Cao c·∫•p</option>
      </select>

      {/* Load Random Sentence */}
      <button onClick={loadRandomSentence} disabled={loading}>
        {loading ? 'Loading...' : 'L·∫•y c√¢u ng·∫´u nhi√™n'}
      </button>

      {/* Target Text Input */}
      <textarea
        value={targetText}
        onChange={(e) => setTargetText(e.target.value)}
        placeholder="Nh·∫≠p ho·∫∑c ch·ªçn c√¢u ti·∫øng Nh·∫≠t ƒë·ªÉ luy·ªán t·∫≠p"
      />

      {/* Recording Controls */}
      <div>
        {!isRecording ? (
          <button onClick={startRecording}>
            B·∫Øt ƒë·∫ßu ghi √¢m
          </button>
        ) : (
          <button onClick={stopRecording}>
            D·ª´ng ghi √¢m
          </button>
        )}
        
        {audioBlob && (
          <>
            <audio src={URL.createObjectURL(audioBlob)} controls />
            <button onClick={resetRecording}>X√≥a</button>
          </>
        )}
      </div>

      {/* Practice Button */}
      <button 
        onClick={handlePractice} 
        disabled={!audioBlob || !targetText || loading}
      >
        {loading ? 'ƒêang x·ª≠ l√Ω...' : 'G·ª≠i ƒë·ªÉ luy·ªán t·∫≠p'}
      </button>

      {/* Error Display */}
      {(error || recordingError) && (
        <div style={{ color: 'red' }}>
          {error || recordingError}
        </div>
      )}

      {/* Results Display */}
      {result && (
        <div>
          <h3>K·∫øt qu·∫£:</h3>
          <p>ƒê·ªô ch√≠nh x√°c: {(result.accuracyScore * 100).toFixed(1)}%</p>
          <p>Ph√°t √¢m: {(result.pronunciationScore * 100).toFixed(1)}%</p>
          <p>T·ªïng ƒëi·ªÉm: {(result.overallScore * 100).toFixed(1)}%</p>
          
          <div>
            <h4>Feedback:</h4>
            <p>{result.feedback.overallFeedbackVi}</p>
            <p>{result.feedback.accuracyFeedbackVi}</p>
            <p>{result.feedback.pronunciationFeedbackVi}</p>
            
            {result.feedback.pronunciationTips.length > 0 && (
              <ul>
                {result.feedback.pronunciationTips.map((tip: string, index: number) => (
                  <li key={index}>{tip}</li>
                ))}
              </ul>
            )}
          </div>

          <div>
            <p>B·∫°n ƒë√£ n√≥i: {result.userTranscript}</p>
            <p>C√¢u m·∫´u: {result.targetText}</p>
          </div>
        </div>
      )}
    </div>
  );
};
```

---

## üì• X·ª≠ L√Ω Response

### Response Structure:

```typescript
interface KaiwaPracticeResult {
  // Scores (0-1, multiply by 100 for percentage)
  accuracyScore: number;        // ƒê·ªô ch√≠nh x√°c so v·ªõi c√¢u m·∫´u
  pronunciationScore: number;  // ƒê·ªô ch√≠nh x√°c ph√°t √¢m
  overallScore: number;        // ƒêi·ªÉm t·ªïng h·ª£p
  
  // Flags
  isAccurate: boolean;         // accuracyScore >= threshold
  needsPractice: boolean;      // overallScore < threshold
  
  // Transcripts
  targetText: string;          // C√¢u m·∫´u
  userTranscript: string;      // C√¢u user ƒë√£ n√≥i
  
  // Feedback (ti·∫øng Vi·ªát)
  feedback: {
    overallFeedbackVi: string;
    accuracyFeedbackVi: string;
    pronunciationFeedbackVi: string;
    suggestionsVi: string;
    pronunciationTips: string[];
  };
}
```

### C√°ch hi·ªÉn th·ªã scores:

```typescript
// Convert score (0-1) to percentage
const scoreToPercentage = (score: number): number => {
  return Math.round(score * 100);
};

// Example: result.overallScore = 0.92 ‚Üí 92%
const percentage = scoreToPercentage(result.overallScore);
```

---

## ‚ö†Ô∏è Error Handling

### Common Errors:

```typescript
// 1. Invalid audio format
if (response.message.includes('Invalid audio format')) {
  // Show: "ƒê·ªãnh d·∫°ng audio kh√¥ng h·ª£p l·ªá. Vui l√≤ng th·ª≠ l·∫°i."
}

// 2. Invalid JLPT level
if (response.message.includes('Invalid JLPT level')) {
  // Show: "Tr√¨nh ƒë·ªô kh√¥ng h·ª£p l·ªá. Vui l√≤ng ch·ªçn N5-N1."
}

// 3. Audio too large
if (response.message.includes('exceed 10MB')) {
  // Show: "File audio qu√° l·ªõn (t·ªëi ƒëa 10MB). Vui l√≤ng ghi √¢m ng·∫Øn h∆°n."
}

// 4. Transcription failed
if (response.message.includes('Could not transcribe')) {
  // Show: "Kh√¥ng th·ªÉ nh·∫≠n di·ªán gi·ªçng n√≥i. Vui l√≤ng n√≥i r√µ r√†ng h∆°n."
}

// 5. Network error
try {
  await kaiwaService.practiceKaiwa(request);
} catch (err) {
  if (err.code === 'ECONNABORTED') {
    // Timeout
    setError('Request timeout. Vui l√≤ng th·ª≠ l·∫°i.');
  } else if (!err.response) {
    // Network error
    setError('Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn server. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi.');
  } else {
    // Server error
    setError(err.response.data?.message || 'C√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i.');
  }
}
```

---

## ‚úÖ Best Practices

### 1. Audio Recording:
- ‚úÖ S·ª≠ d·ª•ng `sampleRate: 16000` (16kHz) - t·ªët nh·∫•t cho ti·∫øng Nh·∫≠t
- ‚úÖ Enable `echoCancellation`, `noiseSuppression`, `autoGainControl`
- ‚úÖ Validate audio size tr∆∞·ªõc khi g·ª≠i (max 10MB)
- ‚úÖ Show loading state khi ƒëang record

### 2. Base64 Encoding:
- ‚úÖ Remove data URL prefix (`data:audio/webm;base64,`) tr∆∞·ªõc khi g·ª≠i
- ‚úÖ Ch·ªâ g·ª≠i ph·∫ßn Base64 string thu·∫ßn

### 3. API Calls:
- ‚úÖ Set timeout h·ª£p l√Ω (30s cho audio processing)
- ‚úÖ Show loading indicator khi ƒëang x·ª≠ l√Ω
- ‚úÖ Handle errors gracefully v·ªõi message ti·∫øng Vi·ªát

### 4. User Experience:
- ‚úÖ Cho ph√©p user ch·ªçn level tr∆∞·ªõc khi practice
- ‚úÖ C√≥ th·ªÉ t·ª± nh·∫≠p c√¢u ho·∫∑c ch·ªçn c√¢u m·∫´u
- ‚úÖ Hi·ªÉn th·ªã audio playback ƒë·ªÉ user nghe l·∫°i
- ‚úÖ Show scores v√† feedback r√µ r√†ng
- ‚úÖ Cho ph√©p practice l·∫°i nhi·ªÅu l·∫ßn

### 5. Performance:
- ‚úÖ Cleanup MediaRecorder khi component unmount
- ‚úÖ Stop all tracks ƒë·ªÉ release microphone
- ‚úÖ Debounce API calls n·∫øu c·∫ßn

### 6. Code Structure:
```typescript
// Recommended folder structure:
src/
  components/
    KaiwaPractice.tsx
  hooks/
    useAudioRecorder.ts
  services/
    kaiwaService.ts
  utils/
    audioUtils.ts
  types/
    kaiwa.types.ts
```

---

## üîó Related APIs

### Get Default Settings:
```typescript
GET /api/ai/defaults

// Returns default language, voice settings for Vietnamese users
```

### Text to Speech (Optional - ƒë·ªÉ ph√°t c√¢u m·∫´u):
```typescript
POST /api/ai/text-to-speech

Request:
{
  "text": "ÁßÅ„ÅØÊó•Êú¨Ë™û„ÇíÂãâÂº∑„Åó„Å¶„ÅÑ„Åæ„Åô",
  "voice": "ja-JP-Standard-A",
  "speed": "normal",
  "audioFormat": "mp3"
}

Response:
{
  "success": true,
  "data": {
    "audioData": "base64_encoded_audio",
    "audioFormat": "mp3"
  }
}
```

---

## üìù Notes

1. **Audio Format**: Browser th∆∞·ªùng record WebM/Opus, nh∆∞ng BE s·∫Ω t·ª± convert sang WAV. B·∫°n ch·ªâ c·∫ßn g·ª≠i Base64 string.

2. **Level Selection**: User ph·∫£i ch·ªçn level (N5-N1) tr∆∞·ªõc khi practice. Level n√†y ·∫£nh h∆∞·ªüng ƒë·∫øn:
   - Scoring thresholds
   - Tolerance cho accuracy
   - Feedback messages

3. **Scores**: T·∫•t c·∫£ scores l√† s·ªë th·∫≠p ph√¢n t·ª´ 0-1. Nh√¢n v·ªõi 100 ƒë·ªÉ hi·ªÉn th·ªã ph·∫ßn trƒÉm.

4. **Feedback**: T·∫•t c·∫£ feedback ƒë·ªÅu b·∫±ng ti·∫øng Vi·ªát, ph√π h·ª£p cho ng∆∞·ªùi Vi·ªát h·ªçc ti·∫øng Nh·∫≠t.

5. **Timeout**: Audio processing c√≥ th·ªÉ m·∫•t 10-30 gi√¢y t√πy ƒë·ªô d√†i audio. N√™n set timeout h·ª£p l√Ω.

---

## üêõ Troubleshooting

### Microphone kh√¥ng ho·∫°t ƒë·ªông:
- Check browser permissions
- Test v·ªõi `navigator.mediaDevices.getUserMedia()`
- Check HTTPS (required for microphone access)

### Audio qu√° l·ªõn:
- Gi·ªõi h·∫°n th·ªùi gian record (v√≠ d·ª•: max 30 gi√¢y)
- Compress audio n·∫øu c·∫ßn

### API timeout:
- TƒÉng timeout l√™n 60s n·∫øu c·∫ßn
- Show progress indicator

### Base64 encoding l·ªói:
- ƒê·∫£m b·∫£o remove data URL prefix
- Check blob type tr∆∞·ªõc khi encode

---

## üìû Support

N·∫øu c√≥ v·∫•n ƒë·ªÅ, check:
1. Browser console logs
2. Network tab trong DevTools
3. Backend logs
4. Swagger UI: `/swagger-ui.html` ƒë·ªÉ test API tr·ª±c ti·∫øp

---

**Ch√∫c b·∫°n t√≠ch h·ª£p th√†nh c√¥ng! üéâ**

